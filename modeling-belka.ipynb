{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-02-21T13:56:05.144136Z","iopub.execute_input":"2025-02-21T13:56:05.144671Z","iopub.status.idle":"2025-02-21T13:56:05.153495Z","shell.execute_reply.started":"2025-02-21T13:56:05.144620Z","shell.execute_reply":"2025-02-21T13:56:05.152421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install rdkit ","metadata":{"execution":{"iopub.status.busy":"2025-02-21T13:56:05.155534Z","iopub.execute_input":"2025-02-21T13:56:05.156017Z","iopub.status.idle":"2025-02-21T13:56:18.561875Z","shell.execute_reply.started":"2025-02-21T13:56:05.155976Z","shell.execute_reply":"2025-02-21T13:56:18.560645Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Overall\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# For Random Forest\nfrom scipy.sparse import csr_matrix\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.ensemble import RandomForestClassifier\n\n# For Neural Network\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# For KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2025-02-21T13:56:18.563566Z","iopub.execute_input":"2025-02-21T13:56:18.563861Z","iopub.status.idle":"2025-02-21T13:56:31.762877Z","shell.execute_reply.started":"2025-02-21T13:56:18.563835Z","shell.execute_reply":"2025-02-21T13:56:31.762061Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/leash-BELKA/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:56:31.764191Z","iopub.execute_input":"2025-02-21T13:56:31.764692Z","iopub.status.idle":"2025-02-21T13:56:38.529578Z","shell.execute_reply.started":"2025-02-21T13:56:31.764668Z","shell.execute_reply":"2025-02-21T13:56:38.528476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert SMILES\ndef smiles_to_fingerprint(smiles, n_bits=2048):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return np.zeros(n_bits)\n    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits))","metadata":{"execution":{"iopub.status.busy":"2025-02-21T13:56:38.532043Z","iopub.execute_input":"2025-02-21T13:56:38.532363Z","iopub.status.idle":"2025-02-21T13:56:38.537561Z","shell.execute_reply.started":"2025-02-21T13:56:38.532339Z","shell.execute_reply":"2025-02-21T13:56:38.536603Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load train in smaller chunks\nfilename = '/kaggle/input/leash-BELKA/train.csv'\nchunk_size = 100000  # Chunk Size - Tested 30k,100k,300k,500k - 1M (does not work)\nnrows = 500000  # Number of rows to read\n\n# Process data chunks\nchunks = []\n#pd.read_parquet('train.parquet')\nfor chunk in pd.read_csv(filename, chunksize=chunk_size, nrows=nrows):\n    chunk['fingerprints'] = chunk['molecule_smiles'].apply(smiles_to_fingerprint)\n    chunks.append(chunk)\n\n# Concatenate all chunks into single DataFrame\ntrain_df = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-21T13:56:38.538662Z","iopub.execute_input":"2025-02-21T13:56:38.538944Z","execution_failed":"2025-02-21T16:38:39.372Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.columns","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-21T16:38:39.373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-21T16:38:39.373Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Random Forest (Baseline Model)","metadata":{}},{"cell_type":"code","source":"# Separate features (X) and target variable (y)\nX = np.array(train_df['fingerprints'].tolist())\ny = train_df['binds'].values\n\n# Filter out constants for X\nnon_constant_columns = np.any(X != X[0, :], axis=0)\nX = X[:, non_constant_columns]\n\n# Convert X to sparse matrix\nX_sparse = csr_matrix(X)\n\n# Split data \nX_train, X_val, y_train, y_val = train_test_split(X_sparse, y, test_size=0.2, random_state=42)\n\n# Instantiate score function\nk_best = SelectKBest(score_func=f_classif, k=10)  # Adjust K \n\n# Fit and transform\nX_train_kbest = k_best.fit_transform(X_train, y_train)\nX_val_kbest = k_best.transform(X_val)\n\n# Train Model on reduced feature set\nrf_class = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_class.fit(X_train_kbest, y_train)\n\n# Predict on validation data\ny_pred = rf_class.predict(X_val_kbest)\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:45:05.792990Z","iopub.execute_input":"2025-02-21T16:45:05.793911Z","iopub.status.idle":"2025-02-21T16:45:06.112211Z","shell.execute_reply.started":"2025-02-21T16:45:05.793815Z","shell.execute_reply":"2025-02-21T16:45:06.110893Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Neural Network(s)","metadata":{}},{"cell_type":"code","source":"# Separate features (X) and target variable (y)\nX = np.array(train_df['fingerprints'].tolist())\ny = train_df['binds'].values\n\n# Filter out constants for X\nnon_constant_columns = np.any(X != X[0, :], axis=0)\nX = X[:, non_constant_columns]\n\n# Convert X to sparse matrix\nX_sparse = csr_matrix(X)\n\n# Split data \nX_train, X_val, y_train, y_val = train_test_split(X_sparse, y, test_size=0.2, random_state=42)","metadata":{"execution":{"execution_failed":"2025-02-21T16:38:39.373Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nn_model = Sequential([\n    Dense(512, input_shape=(X_train.shape[1],), activation='relu'),\n    Dropout(0.3),\n    Dense(256, activation='relu'),\n    Dropout(0.3),\n    Dense(128, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile \nnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define early stopping - helps overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train \ntrain_nn = nn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=512, callbacks=[early_stopping])\n\n# Evaluate the model on the validation data\nloss, accuracy = nn_model.evaluate(X_val, y_val)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.idle":"2025-02-21T14:25:17.824601Z","shell.execute_reply.started":"2025-02-21T14:14:20.728351Z","shell.execute_reply":"2025-02-21T14:25:17.823578Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"code","source":"# Separate features (X) and target variable (y)\nX = np.array(train_df['fingerprints'].tolist())\ny = train_df['binds'].values\n\n# Balance w/ undersampling (?)\nrus = RandomUnderSampler(random_state=42)\nX_resampled, y_resampled = rus.fit_resample(X, y)\n\n# Split\nX_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n\n# Train model\nknn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\nknn.fit(X_train, y_train)\n\n# Predict\ny_pred = knn.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Validation Accuracy:\", accuracy)\nprint(\"Classification Report:\\n\", classification_report(y_val, y_pred))","metadata":{"execution":{"iopub.status.busy":"2025-02-21T14:25:17.825947Z","iopub.execute_input":"2025-02-21T14:25:17.826295Z","iopub.status.idle":"2025-02-21T14:25:27.612480Z","shell.execute_reply.started":"2025-02-21T14:25:17.826266Z","shell.execute_reply":"2025-02-21T14:25:27.611388Z"},"trusted":true},"outputs":[],"execution_count":null}]}